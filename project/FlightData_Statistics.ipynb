{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efedd730-4a52-4b48-a21d-62b3ee97df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.stat import Summarizer\n",
    "from helpers.helper_functions import translate_to_file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1878cb3a-f626-4920-bb34-d6c8badc73c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = translate_to_file_string(\"../data/Flight_Delay_Jan_2020_ontime.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07096c67-2915-46e2-a648-d88d8acb97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "       .builder\n",
    "       .appName(\"FlightDataStatistics\")\n",
    "       .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b7c93-f6ba-4307-ba66-8acca908cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysparkDF = spark.read.option(\"header\", \"true\") \\\n",
    "       .option(\"inferSchema\", \"true\") \\\n",
    "       .option(\"delimiter\", \",\") \\\n",
    "       .csv(inputFile)\n",
    "print(pysparkDF.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9772f6e-ecaa-4799-b482-a1ef317d5132",
   "metadata": {},
   "source": [
    "Die Anzahl der Spalten kann mit dem Befehl `len(pysparkDF.columns)` berechnet werden. Dabei liefert `DataFrame.columns` eine Liste aller Spalten. Die Länge der Einträge kann anschließend mit `len()` abgerufen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab836947-2ca1-4580-8b7d-aed7f2530788",
   "metadata": {},
   "outputs": [],
   "source": [
    "anzahlSpalten = len(pysparkDF.columns)\n",
    "print(\"Der Datensatz enthält \" + str(anzahlSpalten) + \" Spalten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c15bf-4598-4e69-9619-2dd543da8dcf",
   "metadata": {},
   "source": [
    "Die Anzahl der Zeilen kann mit dem Befehl `DataFrame.count()` ausgegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82281be-f3ce-427c-830f-9684976f19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anzahlZeilen = pysparkDF.count()\n",
    "print(\"Der Datensatz enthält \" + str(anzahlZeilen) + \" Zeilen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54f3bc-e3e2-48d2-a477-e81f91fed4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysparkDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df705cf-804b-47ef-9556-15c19970847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysparkDF.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07867d77-a1c4-4431-ab6e-8295aa8fd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasDf = pysparkDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb93e81-1974-4750-a707-9e2767732261",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3bb162-b284-43f1-84d7-77fd384f1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasDf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7320db-0850-4e7d-a4ce-afc976406f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
