{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d40df1-33d4-4845-8100-7b15f96be4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.ml.stat import Summarizer\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler\n",
    "from helpers.helper_functions import translate_to_file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb235b29-0dc0-4efa-b572-63dbc88bedec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = translate_to_file_string(\"../data/Flight_Delay_Jan_2020_ontime.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a794193-0fee-4f5b-ab7d-d04f71168efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "       .builder\n",
    "       .appName(\"FlightDataStatistics\")\n",
    "       .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81c97e-929d-49db-915a-b88d5cf4e7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysparkDF = spark.read.option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"delimiter\", \",\") \\\n",
    "        .csv(inputFile) \\\n",
    "        .withColumn(\"DIVERTED_BOOL\", expr(\"DIVERTED\").cast(BooleanType())) \\\n",
    "        .withColumn(\"CANCELLED_BOOL\", expr(\"CANCELLED\").cast(BooleanType())) \\\n",
    "        .withColumn(\"DEP_DEL15_BOOL\", expr(\"DEP_DEL15\").cast(BooleanType())) \\\n",
    "        .withColumn(\"ARR_DEL15_BOOL\", expr(\"ARR_DEL15\").cast(BooleanType())) \\\n",
    "        \n",
    "pysparkDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16690424-37a7-4583-9592-bf53bd56c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA UNDERSTANDING!\n",
    "# Check whether OP_CARRIER_FL_NUM is merely running id for flights or rather encoding specific trims (e.g. Istanbul -> New York)\n",
    "pysparkDF.groupby('OP_CARRIER_FL_NUM').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2917b10-342b-4032-b0ef-cde565dab64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA UNDERSTANDING!\n",
    "# A tail number refers to an identification number painted on an aircraft, frequently on the tail.\n",
    "# Check amount of flights per plane\n",
    "pysparkDF.groupby('TAIL_NUM').count().show()\n",
    "\n",
    "# Check average flights per plane per year\n",
    "pysparkDF.groupby('TAIL_NUM').count().agg(F.mean('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9feb0f3-b715-400e-8395-db318f6934ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA UNDERSTANDING!\n",
    "# Check whether ORIGIN_AIRPORT_ID is 1:1 mapping onto ORIGIN\n",
    "pysparkDF.groupby(['ORIGIN_AIRPORT_ID','ORIGIN']).count().count() == pysparkDF.groupby(['ORIGIN_AIRPORT_ID','ORIGIN']).count().dropDuplicates(['ORIGIN_AIRPORT_ID']).count()\n",
    "\n",
    "# -> ORIGIN_AIRPORT_ID is string indexing ORIGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f080c9d-7c73-4262-b5a6-8908149778ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA UNDERSTANDING!\n",
    "# Check whether ORIGIN_AIRPORT_ID is 1:1 mapping onto ORIGIN_AIRPORT_SEQ_ID\n",
    "pysparkDF.groupby(['ORIGIN_AIRPORT_ID','ORIGIN_AIRPORT_SEQ_ID']).count().count() == pysparkDF.groupby(['ORIGIN_AIRPORT_ID','ORIGIN_AIRPORT_SEQ_ID']).count().dropDuplicates(['ORIGIN_AIRPORT_ID']).count()\n",
    "\n",
    "# -> ORIGIN_AIRPORT_ID is 1:1 mapping to ORIGIN_AIRPORT_SEQ_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee88c9b-ecc1-4fa0-b6a4-b72087f84563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA UNDERSTANDING!\n",
    "# Check whether DEST_AIRPORT_ID is 1:1 mapping onto DEST\n",
    "pysparkDF.groupby(['DEST_AIRPORT_ID','DEST']).count().count() == pysparkDF.groupby(['DEST_AIRPORT_ID','DEST']).count().dropDuplicates(['DEST_AIRPORT_ID']).count()\n",
    "\n",
    "# -> DEST_AIRPORT_ID is string indexing DEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758a09bc-a7a7-4701-ab66-dad738b6d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA UNDERSTANDING!\n",
    "# Check whether DEST_AIRPORT_ID is 1:1 mapping onto DEST_AIRPORT_SEQ_ID\n",
    "pysparkDF.groupby(['DEST_AIRPORT_ID','DEST_AIRPORT_SEQ_ID']).count().count() == pysparkDF.groupby(['DEST_AIRPORT_ID','DEST_AIRPORT_SEQ_ID']).count().dropDuplicates(['DEST_AIRPORT_SEQ_ID']).count()\n",
    "\n",
    "# -> DEST_AIRPORT_ID is 1:1 mapping to ORIGIN_AIRPORT_SEQ_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2b0cd7-b51e-40cd-bdc9-3d6917254eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA UNDERSTANDING!\n",
    "# Check whether OP_UNIQUE_CARRIER is 1:1 mapping onto OP_CARRIER\n",
    "pysparkDF.groupby(['OP_UNIQUE_CARRIER','OP_CARRIER']).count().count() == pysparkDF.groupby(['OP_UNIQUE_CARRIER','OP_CARRIER']).count().dropDuplicates(['OP_UNIQUE_CARRIER']).count()\n",
    "\n",
    "# -> OP_UNIQUE_CARRIER is 1:1 mapping to OP_CARRIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9613f2-a306-4f71-b8b7-48c3d9b67578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA UNDERSTANDING!\n",
    "# Check whether TAIL_NUM is 1:1 mapping onto OP_CARRIER_FL_NUM\n",
    "pysparkDF.groupby(['TAIL_NUM','OP_CARRIER_FL_NUM']).count().count() == pysparkDF.groupby(['TAIL_NUM','OP_CARRIER_FL_NUM']).count().dropDuplicates(['OP_CARRIER_FL_NUM']).count()\n",
    "\n",
    "# -> TAIL_NUM is not 1:1 mapping to OP_CARRIER_FL_NUM -> One distinct plane can fly multiple routes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb783a-d512-49ff-afb8-145b852ff68b",
   "metadata": {},
   "source": [
    "### Remove faulty features\n",
    "Bei der Spalte \"_c21\" handelt es sich um eine leere Spalte. Die Spalte enthält keine Daten und kann somit entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd1f21-4dd2-443a-80ee-2d9a4be1cbc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pysparkDF = pysparkDF.drop('_c21')\n",
    "pysparkDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d069aa-0c9c-4bec-87b6-fee149db57b1",
   "metadata": {},
   "source": [
    "### Remove records containing NULL values\n",
    "Der Datensatz enthält Felder mit NULL Werten. Diese werden für die Auswertung enfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a1ce3-5ff6-4521-be22-2acafffd4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysparkDF_nonull = pysparkDF.dropna()\n",
    "f\"Removed {pysparkDF.count()-pysparkDF_nonull.count()} records containing NULL values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead53265-6305-4ed0-a9e9-d6a150663c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
