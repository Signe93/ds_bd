{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa13e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# for pretty printing\n",
    "def printDf(sprkDF): \n",
    "    newdf = sprkDF.toPandas()\n",
    "    from IPython.display import display, HTML\n",
    "    return HTML(newdf.to_html())\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "# Spark libs\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "# helper functions\n",
    "from helpers.helper_functions import translate_to_file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dafa438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.ml.stat import Summarizer\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler\n",
    "from helpers.helper_functions import translate_to_file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = translate_to_file_string(\"../data/Flight_Delay_Jan_2020_ontime.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05552ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "       .builder\n",
    "       .appName(\"FlightDataStatistics\")\n",
    "       .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysparkDF = spark.read.option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"delimiter\", \",\") \\\n",
    "        .csv(inputFile) \\\n",
    "        \n",
    "pysparkDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1db6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of columns\n",
    "anzahlSpalten = len(pysparkDF.columns)\n",
    "print(\"Der Datensatz enthält \" + str(anzahlSpalten) + \" Spalten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows\n",
    "anzahlZeilen = pysparkDF.count()\n",
    "print(\"Der Datensatz enthält \" + str(anzahlZeilen) + \" Zeilen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b543db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether OP_CARRIER_FL_NUM is merely running id for flights or rather encoding specific trips (e.g. Istanbul -> New York)\n",
    "pysparkDF.groupby('OP_CARRIER_FL_NUM').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932bd310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tail number refers to an identification number painted on an aircraft, frequently on the tail.\n",
    "# Check amount of flights per plane\n",
    "pysparkDF.groupby('TAIL_NUM').count().show()\n",
    "\n",
    "# Check average flights per plane per year\n",
    "pysparkDF.groupby('TAIL_NUM').count().agg(F.mean('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aeeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether ORIGIN_AIRPORT_ID is 1:1 mapping onto ORIGIN\n",
    "pysparkDF.groupby(['ORIGIN_AIRPORT_ID','ORIGIN']).count().count() == pysparkDF.groupby(['ORIGIN_AIRPORT_ID','ORIGIN']).count().dropDuplicates(['ORIGIN_AIRPORT_ID']).count()\n",
    "\n",
    "# -> ORIGIN_AIRPORT_ID is string indexing ORIGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeec896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether ORIGIN_AIRPORT_ID is 1:1 mapping onto ORIGIN_AIRPORT_SEQ_ID\n",
    "pysparkDF.groupby(['ORIGIN_AIRPORT_ID','ORIGIN_AIRPORT_SEQ_ID']).count().count() == pysparkDF.groupby(['ORIGIN_AIRPORT_ID','ORIGIN_AIRPORT_SEQ_ID']).count().dropDuplicates(['ORIGIN_AIRPORT_ID']).count()\n",
    "\n",
    "# -> ORIGIN_AIRPORT_ID is 1:1 mapping to ORIGIN_AIRPORT_SEQ_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1bb589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether DEST_AIRPORT_ID is 1:1 mapping onto DEST\n",
    "pysparkDF.groupby(['DEST_AIRPORT_ID','DEST']).count().count() == pysparkDF.groupby(['DEST_AIRPORT_ID','DEST']).count().dropDuplicates(['DEST_AIRPORT_ID']).count()\n",
    "\n",
    "# -> DEST_AIRPORT_ID is string indexing DEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether DEST_AIRPORT_ID is 1:1 mapping onto DEST_AIRPORT_SEQ_ID\n",
    "pysparkDF.groupby(['DEST_AIRPORT_ID','DEST_AIRPORT_SEQ_ID']).count().count() == pysparkDF.groupby(['DEST_AIRPORT_ID','DEST_AIRPORT_SEQ_ID']).count().dropDuplicates(['DEST_AIRPORT_SEQ_ID']).count()\n",
    "\n",
    "# -> DEST_AIRPORT_ID is 1:1 mapping to ORIGIN_AIRPORT_SEQ_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether OP_UNIQUE_CARRIER is 1:1 mapping onto OP_CARRIER\n",
    "pysparkDF.groupby(['OP_UNIQUE_CARRIER','OP_CARRIER']).count().count() == pysparkDF.groupby(['OP_UNIQUE_CARRIER','OP_CARRIER']).count().dropDuplicates(['OP_UNIQUE_CARRIER']).count()\n",
    "\n",
    "# -> OP_UNIQUE_CARRIER is 1:1 mapping to OP_CARRIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether TAIL_NUM is 1:1 mapping onto OP_CARRIER_FL_NUM\n",
    "pysparkDF.groupby(['TAIL_NUM','OP_CARRIER_FL_NUM']).count().count() == pysparkDF.groupby(['TAIL_NUM','OP_CARRIER_FL_NUM']).count().dropDuplicates(['OP_CARRIER_FL_NUM']).count()\n",
    "\n",
    "# -> TAIL_NUM is not 1:1 mapping to OP_CARRIER_FL_NUM -> One distinct plane can fly multiple routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bad3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Dataframe to Pandas \n",
    "pandasDF =pysparkDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6dc4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excerpt from the dataset\n",
    "pandasDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c65a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key figures\n",
    "pandasDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e81412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of flights delayed and on time \n",
    "print(\"Anzahl an pünktlichen (0) und verspäteten (1) Flügen beim Abflug\")\n",
    "print(pandasDF['DEP_DEL15'].value_counts())\n",
    "\n",
    "print(\"Anzahl an pünktlichen (0) und verspäteten (1) Flügen bei der Ankunft\")\n",
    "print(pandasDF['ARR_DEL15'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e527584-cd1f-432e-b1ef-63d0c8966525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show cancelled, diverted and delayed flight counts and total distance per Carrier in a table\n",
    "groupCarrier = pandasDF.groupby(\"OP_CARRIER\")\n",
    "groupCarrier[['CANCELLED', \"DIVERTED\",'ARR_DEL15', 'DEP_DEL15', 'DISTANCE']].sum().sort_values([\"CANCELLED\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04ff0f7-0c3d-4caa-80b5-2f972c95be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show cancelled, diverted and delayed flight counts and total distance per origin airport in a table\n",
    "groupDeprature = pandasDF.groupby(\"ORIGIN\")\n",
    "groupDeprature[['CANCELLED', \"DIVERTED\",'DEP_DEL15', 'DISTANCE']].sum().sort_values([\"DISTANCE\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d12b03",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d780bc42",
   "metadata": {},
   "source": [
    "Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddbd60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysparkDF.drop('OP_CARRIER','DEST','DEST_AIRPORT_SEQ_ID','OP_UNIQUE_CARRIER', 'ORIGIN_AIRPORT_SEQ_ID', 'ORIGIN', '_c21', 'TAIL_NUM', 'OP_CARRIER_FL_NUM').toPandas().hist(bins=50, figsize=(20,15))\n",
    "save_fig(\"attribute_histogram_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334e83c",
   "metadata": {},
   "source": [
    "Stacked Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd8c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Count of flights delayed and on time\n",
    "\n",
    "# Create bars for filtered value delayed (1) and on time (0)\n",
    "ax = pysparkDF.groupby([\"OP_CARRIER\",\"DEP_DEL15\"]).count().filter(pysparkDF.DEP_DEL15 == 0).toPandas().sort_values(by=\"OP_CARRIER\",ascending=True).plot.bar(stacked=True, x=\"OP_CARRIER\", color='Blue')\n",
    "pysparkDF.groupby([\"OP_CARRIER\",\"DEP_DEL15\"]).count().filter(pysparkDF.DEP_DEL15 == 1).toPandas().sort_values(by=\"OP_CARRIER\",ascending=True).plot.bar(stacked=True, x=\"OP_CARRIER\", color='Orange', ax=ax )\n",
    "\n",
    "\n",
    "plt.ylabel(\"Count Flight\")\n",
    "\n",
    "save_fig(\"stacked_bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e10bf",
   "metadata": {},
   "source": [
    "Grouped Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee67ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show count of cancelled, diverted and delayed flights per airline\n",
    "pandasDF.groupby(by=\"OP_CARRIER\")[['OP_CARRIER','CANCELLED', \"DIVERTED\",'ARR_DEL15']].sum().plot.bar()\n",
    "\n",
    "save_fig(\"grouped_bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec87f2",
   "metadata": {},
   "source": [
    "Bar Chart 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35654ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart with normalized values\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "Data = pd.read_csv('../data/Flight_Delay_Jan_2020_ontime.csv')\n",
    "Data.head()\n",
    "\n",
    "x,y = 'DAY_OF_WEEK', 'DEP_DEL15'\n",
    "\n",
    "#Normalize Counts\n",
    "(Data\n",
    ".groupby(x)[y]\n",
    ".value_counts(normalize=True)\n",
    ".mul(100)\n",
    ".rename('percentage')\n",
    ".reset_index()\n",
    ".pipe((sns.catplot,'data'), x= 'DAY_OF_WEEK',y='percentage',hue=y, kind='bar'))\n",
    "\n",
    "\n",
    "save_fig(\"normalized_bar\")\n",
    "# show the graph\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9182088a",
   "metadata": {},
   "source": [
    "Pie Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pie Chart - Show Cancelled Flights as pecentage per day of week\n",
    "pysparkDF.groupby(\"DAY_OF_WEEK\", \"CANCELLED\").count().filter(pysparkDF.CANCELLED==1).toPandas().plot.pie(y=\"DAY_OF_WEEK\", autopct=\"%.1f%%\", legend=False)\n",
    "plt.suptitle(\"Cancelled Flights\")\n",
    "save_fig(\"pie_chart\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3306b21",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b408947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Correlation of attributes\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "plt.figure(figsize = (12, 10))\n",
    "sns.heatmap(pandasDF.corr(), annot = True, cmap = 'vlag')\n",
    "save_fig(\"correlation_heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573fe95",
   "metadata": {},
   "source": [
    "Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot for delayed flights \n",
    "ax = pysparkDF.select(\"OP_CARRIER_AIRLINE_ID\", \"ORIGIN_AIRPORT_ID\").filter(pysparkDF.ARR_DEL15 != 0).toPandas().plot.scatter(x='OP_CARRIER_AIRLINE_ID', y='ORIGIN_AIRPORT_ID', color='DarkBlue', label='ARR_DEL15 1')\n",
    "pysparkDF.select(\"OP_CARRIER_AIRLINE_ID\",\"ORIGIN_AIRPORT_ID\").filter(pysparkDF.DEP_DEL15 != 0).toPandas().plot.scatter(x='OP_CARRIER_AIRLINE_ID', y='ORIGIN_AIRPORT_ID', color='Yellow', label='DEP_DEL15 1', ax=ax)\n",
    "\n",
    "save_fig(\"scatter_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff15eb5",
   "metadata": {},
   "source": [
    "Scatter Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2963cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Matrix for multiple columns\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(pysparkDF.select(\"OP_CARRIER_AIRLINE_ID\", \"ORIGIN_AIRPORT_ID\", \"DEST_AIRPORT_ID\", \"DEP_DEL15\", \"Distance\").toPandas(), alpha=0.2, figsize=(30, 30), diagonal='kde')\n",
    "save_fig(\"scatter_matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6dd62",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6478c44a3317eea7880644b1e90701767b1772da5d4d1e50fe9680e69436a5ad"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
