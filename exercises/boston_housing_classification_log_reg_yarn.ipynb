{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Classification Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from socket import gethostname, gethostbyname\n",
    "from helpers.helper_functions import translate_to_file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"hdfs:///data/Boston_Housing_Data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark session creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "       .builder \n",
    "       .master(\"yarn\")  \n",
    "       .appName(\"BostonHousingClass\")\n",
    "       .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame creation using an ifered Schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRIM: double (nullable = true)\n",
      " |-- ZN: double (nullable = true)\n",
      " |-- INDUS: double (nullable = true)\n",
      " |-- CHAS: integer (nullable = true)\n",
      " |-- NOX: double (nullable = true)\n",
      " |-- RM: double (nullable = true)\n",
      " |-- AGE: double (nullable = true)\n",
      " |-- DIS: double (nullable = true)\n",
      " |-- RAD: integer (nullable = true)\n",
      " |-- TAX: integer (nullable = true)\n",
      " |-- PTRATIO: double (nullable = true)\n",
      " |-- B: double (nullable = true)\n",
      " |-- LSTAT: double (nullable = true)\n",
      " |-- MEDV: double (nullable = true)\n",
      " |-- CAT: integer (nullable = true)\n",
      " |-- CATBOOL: boolean (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "       .option(\"inferSchema\", \"true\") \\\n",
    "       .option(\"delimiter\", \";\") \\\n",
    "       .csv(inputFile) \\\n",
    "       .withColumn(\"CATBOOL\", expr(\"CAT\").cast(BooleanType()))\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "featureCols = df.columns.copy()\n",
    "featureCols.remove(\"MEDV\")\n",
    "featureCols.remove(\"CAT\")\n",
    "featureCols.remove(\"CATBOOL\") \n",
    "print(featureCols)\n",
    "\n",
    "assembler =  VectorAssembler(outputCol=\"features\", inputCols=featureCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labledPointDataSet = assembler.transform(df)\n",
    "splits = labledPointDataSet.randomSplit([0.9, 0.1 ], 12345)\n",
    "training = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Optimize the paramters \n",
    "lr = LogisticRegression(labelCol=\"CAT\",featuresCol=\"features\", maxIter=100, \\\n",
    "                           regParam=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CAT\",rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error\",(1.0 - accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
