{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Decision Tree on the Churn Dataset in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrameReader\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from helpers.helper_functions import translate_to_file_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the churn file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"hdfs:///data/churn.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Spark Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a SparkSession\n",
    "spark = (SparkSession\n",
    "       .builder\n",
    "       .master(\"yarn\") \n",
    "       .appName(\"ChurnDecisionTree\")\n",
    "       .getOrCreate())\n",
    "# create a DataFrame using an ifered Schema \n",
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "       .option(\"inferSchema\", \"true\") \\\n",
    "       .option(\"delimiter\", \";\") \\\n",
    "       .csv(inputFile)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Transform labels into index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COLLEGE: string (nullable = true)\n",
      " |-- INCOME: integer (nullable = true)\n",
      " |-- OVERAGE: integer (nullable = true)\n",
      " |-- LEFTOVER: integer (nullable = true)\n",
      " |-- HOUSE: integer (nullable = true)\n",
      " |-- HANDSET_PRICE: integer (nullable = true)\n",
      " |-- OVER_15MINS_CALLS_PER_MONTH: integer (nullable = true)\n",
      " |-- AVERAGE_CALL_DURATION: integer (nullable = true)\n",
      " |-- REPORTED_SATISFACTION: string (nullable = true)\n",
      " |-- REPORTED_USAGE_LEVEL: string (nullable = true)\n",
      " |-- CONSIDERING_CHANGE_OF_PLAN: string (nullable = true)\n",
      " |-- LEAVE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "\n",
    "labelIndexer = StringIndexer().setInputCol(\"LEAVE\").setOutputCol(\"label\").fit(df)\n",
    "collegeIndexer = StringIndexer().setInputCol(\"COLLEGE\").setOutputCol(\"COLLEGE_NUM\").fit(df)\n",
    "# TODO add additional indexer for string attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Build the feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INCOME', 'OVERAGE', 'LEFTOVER', 'HOUSE', 'HANDSET_PRICE', 'OVER_15MINS_CALLS_PER_MONTH', 'AVERAGE_CALL_DURATION', 'COLLEGE_NUM']\n"
     ]
    }
   ],
   "source": [
    "featureCols = df.columns.copy()\n",
    "featureCols.remove(\"LEAVE\")\n",
    "featureCols.remove(\"COLLEGE\")\n",
    "featureCols.remove(\"REPORTED_SATISFACTION\")\n",
    "featureCols.remove(\"REPORTED_USAGE_LEVEL\")\n",
    "featureCols.remove(\"CONSIDERING_CHANGE_OF_PLAN\")\n",
    "featureCols = featureCols +[\"COLLEGE_NUM\"]\n",
    "print(featureCols)\n",
    "# TODO add additinal columns to feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the feature Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler =  VectorAssembler(outputCol=\"features\", inputCols=list(featureCols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert indexed labels back to original labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predConverter = IndexToString(inputCol=\"prediction\",outputCol=\"predictedLabel\",labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledData = labelIndexer.transform(df)\n",
    "# TODO add the other additional indexer\n",
    "indexedLabedData = collegeIndexer.transform(labeledData)\n",
    "labeledPointData = assembler.transform(indexedLabedData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = labeledPointData.randomSplit([0.6, 0.4 ], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Optimize the properties \n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", impurity=\"entropy\")\n",
    "dtModel = dt.fit(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator =  BinaryClassificationEvaluator(labelCol=\"label\",rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtModel.transform(test)\n",
    "predictionsConverted = predConverter.transform(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate / Test the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------+-----+--------------------+\n",
      "|prediction|label|predictedLabel|LEAVE|            features|\n",
      "+----------+-----+--------------+-----+--------------------+\n",
      "|       0.0|  1.0|          STAY|LEAVE|[20007.0,36.0,23....|\n",
      "|       1.0|  1.0|         LEAVE|LEAVE|[20009.0,183.0,18...|\n",
      "|       1.0|  1.0|         LEAVE|LEAVE|[20022.0,205.0,36...|\n",
      "|       0.0|  0.0|          STAY| STAY|[20074.0,0.0,47.0...|\n",
      "|       0.0|  0.0|          STAY| STAY|(8,[0,3,4,6],[200...|\n",
      "|       0.0|  1.0|          STAY|LEAVE|[20175.0,191.0,23...|\n",
      "|       1.0|  1.0|         LEAVE|LEAVE|[20224.0,223.0,11...|\n",
      "|       1.0|  0.0|         LEAVE| STAY|[20273.0,0.0,30.0...|\n",
      "|       0.0|  0.0|          STAY| STAY|[20278.0,0.0,69.0...|\n",
      "|       0.0|  0.0|          STAY| STAY|[20284.0,0.0,5.0,...|\n",
      "|       1.0|  1.0|         LEAVE|LEAVE|[20288.0,0.0,0.0,...|\n",
      "|       0.0|  1.0|          STAY|LEAVE|[20300.0,0.0,10.0...|\n",
      "|       0.0|  1.0|          STAY|LEAVE|[20317.0,85.0,0.0...|\n",
      "|       1.0|  1.0|         LEAVE|LEAVE|(8,[0,3,4,6],[203...|\n",
      "|       1.0|  1.0|         LEAVE|LEAVE|[20323.0,57.0,0.0...|\n",
      "|       0.0|  1.0|          STAY|LEAVE|[20326.0,88.0,0.0...|\n",
      "|       1.0|  1.0|         LEAVE|LEAVE|[20339.0,48.0,57....|\n",
      "|       0.0|  0.0|          STAY| STAY|[20377.0,0.0,53.0...|\n",
      "|       1.0|  0.0|         LEAVE| STAY|(8,[0,3,4,6],[203...|\n",
      "|       1.0|  1.0|         LEAVE|LEAVE|[20417.0,0.0,0.0,...|\n",
      "+----------+-----+--------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test Error =  0.30965295031055895\n"
     ]
    }
   ],
   "source": [
    "predictionsConverted.select(\"prediction\", \"label\", \"predictedLabel\", \"LEAVE\", \"features\").show()\n",
    "# Select (prediction, true label) and compute test error.\n",
    "   \n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = \" ,(1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
