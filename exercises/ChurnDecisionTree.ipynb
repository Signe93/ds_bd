{"cells":[{"cell_type":"markdown","metadata":{},"source":["# The Decision Tree on the Churn Dataset in Spark"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["from pyspark.sql import DataFrameReader\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import IndexToString, StringIndexer, VectorAssembler\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.ml.classification import DecisionTreeClassifier"]},{"cell_type":"markdown","metadata":{},"source":["## Select the churn file "]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["inputFile = \"../data/churn.csv\""]},{"cell_type":"markdown","metadata":{},"source":["## Create the Spark Session "]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["#create a SparkSession\n","spark = (SparkSession\n","       .builder\n","       .appName(\"ChurnDecisionTree\")\n","       .getOrCreate())\n","# create a DataFrame using an ifered Schema \n","df = spark.read.option(\"header\", \"true\") \\\n","       .option(\"inferSchema\", \"true\") \\\n","       .option(\"delimiter\", \";\") \\\n","       .csv(inputFile)   "]},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation\n","### Transform labels into index"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"root\n |-- COLLEGE: string (nullable = true)\n |-- INCOME: integer (nullable = true)\n |-- OVERAGE: integer (nullable = true)\n |-- LEFTOVER: integer (nullable = true)\n |-- HOUSE: integer (nullable = true)\n |-- HANDSET_PRICE: integer (nullable = true)\n |-- OVER_15MINS_CALLS_PER_MONTH: integer (nullable = true)\n |-- AVERAGE_CALL_DURATION: integer (nullable = true)\n |-- REPORTED_SATISFACTION: string (nullable = true)\n |-- REPORTED_USAGE_LEVEL: string (nullable = true)\n |-- CONSIDERING_CHANGE_OF_PLAN: string (nullable = true)\n |-- LEAVE: string (nullable = true)\n\n"}],"source":["df.printSchema()\n","\n","labelIndexer = StringIndexer().setInputCol(\"LEAVE\").setOutputCol(\"label\").fit(df)\n","collegeIndexer = StringIndexer().setInputCol(\"COLLEGE\").setOutputCol(\"COLLEGE_NUM\").fit(df)\n","# TODO add additional indexer for string attributes\n"]},{"cell_type":"markdown","metadata":{},"source":[" ### Build the feature vector"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"['INCOME', 'OVERAGE', 'LEFTOVER', 'HOUSE', 'HANDSET_PRICE', 'OVER_15MINS_CALLS_PER_MONTH', 'AVERAGE_CALL_DURATION', 'COLLEGE_NUM']\n"}],"source":["featureCols = df.columns.copy()\n","featureCols.remove(\"LEAVE\")\n","featureCols.remove(\"COLLEGE\")\n","featureCols.remove(\"REPORTED_SATISFACTION\")\n","featureCols.remove(\"REPORTED_USAGE_LEVEL\")\n","featureCols.remove(\"CONSIDERING_CHANGE_OF_PLAN\")\n","featureCols = featureCols +[\"COLLEGE_NUM\"]\n","print(featureCols)\n","# TODO add additinal columns to feature vector"]},{"cell_type":"markdown","metadata":{},"source":["### Build the feature Vector Assembler"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["assembler =  VectorAssembler(outputCol=\"features\", inputCols=list(featureCols))"]},{"cell_type":"markdown","metadata":{},"source":["### Convert indexed labels back to original labels"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["predConverter = IndexToString(inputCol=\"prediction\",outputCol=\"predictedLabel\",labels=labelIndexer.labels)"]},{"cell_type":"markdown","metadata":{},"source":["## Do the Data Preparation"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["labeledData = labelIndexer.transform(df)\n","# TODO add the other additional indexer\n","indexedLabedData = collegeIndexer.transform(labeledData)\n","labeledPointData = assembler.transform(indexedLabedData)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Spliting the dataset into train and test set"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":["splits = labeledPointData.randomSplit([0.6, 0.4 ], 1234)\n","train = splits[0]\n","test = splits[1]"]},{"cell_type":"markdown","metadata":{},"source":["## Build the decision tree model"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["# TODO Optimize the properties \n","dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", impurity=\"entropy\")\n","dtModel = dt.fit(train)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Build an evaluator"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["evaluator =  BinaryClassificationEvaluator(labelCol=\"label\",rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")"]},{"cell_type":"markdown","metadata":{},"source":["## Do the prediction "]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["predictions = dtModel.transform(test)\n","predictionsConverted = predConverter.transform(predictions)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate / Test the Model "]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"+----------+-----+--------------+-----+--------------------+\n|prediction|label|predictedLabel|LEAVE|            features|\n+----------+-----+--------------+-----+--------------------+\n|       0.0|  1.0|          STAY|LEAVE|[20007.0,36.0,23....|\n|       1.0|  1.0|         LEAVE|LEAVE|[20009.0,183.0,18...|\n|       1.0|  1.0|         LEAVE|LEAVE|[20012.0,246.0,9....|\n|       1.0|  0.0|         LEAVE| STAY|[20063.0,58.0,0.0...|\n|       1.0|  0.0|         LEAVE| STAY|(8,[0,3,4,6],[200...|\n|       0.0|  0.0|          STAY| STAY|[20078.0,199.0,65...|\n|       0.0|  0.0|          STAY| STAY|(8,[0,3,4,6],[200...|\n|       0.0|  0.0|          STAY| STAY|[20278.0,0.0,69.0...|\n|       0.0|  0.0|          STAY| STAY|[20284.0,0.0,5.0,...|\n|       1.0|  1.0|         LEAVE|LEAVE|[20288.0,0.0,0.0,...|\n|       0.0|  1.0|          STAY|LEAVE|[20317.0,85.0,0.0...|\n|       1.0|  1.0|         LEAVE|LEAVE|(8,[0,3,4,6],[203...|\n|       0.0|  1.0|          STAY|LEAVE|[20326.0,88.0,0.0...|\n|       0.0|  0.0|          STAY| STAY|[20346.0,78.0,20....|\n|       1.0|  0.0|         LEAVE| STAY|(8,[0,3,4,6],[203...|\n|       0.0|  0.0|          STAY| STAY|[20400.0,207.0,0....|\n|       1.0|  1.0|         LEAVE|LEAVE|[20417.0,0.0,0.0,...|\n|       0.0|  1.0|          STAY|LEAVE|[20424.0,0.0,15.0...|\n|       1.0|  1.0|         LEAVE|LEAVE|[20457.0,0.0,32.0...|\n|       1.0|  1.0|         LEAVE|LEAVE|[20497.0,226.0,0....|\n+----------+-----+--------------+-----+--------------------+\nonly showing top 20 rows\n\nTest Error =  0.29755778873437366\n"}],"source":["predictionsConverted.select(\"prediction\", \"label\", \"predictedLabel\", \"LEAVE\", \"features\").show()\n","# Select (prediction, true label) and compute test error.\n","   \n","accuracy = evaluator.evaluate(predictions)\n","print(\"Test Error = \" ,(1.0 - accuracy))"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["spark.stop()"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6-final"}},"nbformat":4,"nbformat_minor":2}