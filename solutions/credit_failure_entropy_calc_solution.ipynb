{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Credit Failure Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from helpers.helper_functions import translate_to_file_string\n",
    "\n",
    "inputFile = translate_to_file_string(\"../data/credit_failure.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bin_entropy (dataframe, label=\"Kreditausfall\"):\n",
    "    \"\"\" calculates the entropy of the given dataframe based on the given label \"\"\"\n",
    "    numRows= dataframe.count()\n",
    "    truefalse = dataframe.groupBy(label).count()\n",
    "    labelvalues = csv.select(label).dropDuplicates()\n",
    "    if labelvalues.count() != 2 :\n",
    "        raise Exception('infalid datafram or label')\n",
    "    else : \n",
    "        labelval0 = labelvalues.collect()[0][0]\n",
    "        labelval1 = labelvalues.collect()[1][0]\n",
    "\n",
    "        return entropy([truefalse.filter(f\"{label} == '{labelval0}'\").select(\"count\").collect()[0][\"count\"] / numRows, \\\n",
    "                truefalse.filter (f\"{label} == '{labelval1}'\").select(\"count\").collect()[0][\"count\"] / numRows ], base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---+-----------+-----------+------------+-------------+\n",
      "| ID|   Kopfform|Koerperform|Koerperfarbe|Kreditausfall|\n",
      "+---+-----------+-----------+------------+-------------+\n",
      "|  0|Quadratisch|       Oval|       weiss|           No|\n",
      "|  1|       Rund|       Oval|     schwarz|          Yes|\n",
      "|  2|Quadratisch|   Rechteck|       weiss|          Yes|\n",
      "|  3|Quadratisch|   Rechteck|       weiss|          Yes|\n",
      "|  4|Quadratisch|   Rechteck|       weiss|          Yes|\n",
      "|  5|       Rund|   Rechteck|     schwarz|           No|\n",
      "|  6|Quadratisch|   Rechteck|       weiss|          Yes|\n",
      "|  7|Quadratisch|       Oval|       weiss|           No|\n",
      "|  8|Quadratisch|       Oval|       weiss|           No|\n",
      "|  9|Quadratisch|   Rechteck|       weiss|          Yes|\n",
      "| 10|Quadratisch|       Oval|       weiss|           No|\n",
      "| 11|       Rund|       Oval|       weiss|          Yes|\n",
      "+---+-----------+-----------+------------+-------------+\n",
      "\n",
      "0.9798687566511527\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "             .builder\n",
    "             .appName(\"Entropy\")\n",
    "             .getOrCreate())\n",
    "\n",
    "csv = spark.read.option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .option(\"delimiter\", \";\") \\\n",
    "        .csv(inputFile)\n",
    "csv.show()\n",
    "\n",
    "baseEntropy = calc_bin_entropy(csv) \n",
    "print (baseEntropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9182958340544894\n",
      "0.9910760598382222\n"
     ]
    }
   ],
   "source": [
    "kopfformRundEntropy = calc_bin_entropy(csv.filter(\"Kopfform == 'Rund'\"))\n",
    "print (kopfformRundEntropy)\n",
    "kopfformQuadratischEntropy = calc_bin_entropy(csv.filter(\"Kopfform == 'Quadratisch'\"))\n",
    "print (kopfformQuadratischEntropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6500224216483541\n",
      "0.9182958340544894\n"
     ]
    }
   ],
   "source": [
    "koerperFormRechteck = calc_bin_entropy(csv.filter(\"Koerperform == 'Rechteck'\"))\n",
    "print (koerperFormRechteck)\n",
    "koerperFormOval = calc_bin_entropy(csv.filter(\"Koerperform == 'Oval'\"))\n",
    "print (koerperFormOval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9709505944546688\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "koerperfarbeWeiss = calc_bin_entropy(csv.filter(\"Koerperfarbe == 'weiss'\"))\n",
    "print (koerperfarbeWeiss)\n",
    "koerperfarbeSchwarz = calc_bin_entropy(csv.filter(\"Koerperfarbe == 'schwarz'\"))\n",
    "print (koerperfarbeSchwarz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}